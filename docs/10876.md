# 数据的五个阶段

> 原文：<https://dev.to/korenmiklos/the-five-stages-of-data-3dnl>

几年前，我就在思考数据如何变成数据。在可用于分析之前，它要经过哪些阶段？在我们的研究小组中，我们每天都依赖以下模型。

[![Illustration: Emiliano Ponzi for the New Yorker.](img/2491e488693b1dd79f43d03044465334.png)](https://res.cloudinary.com/practicaldev/image/fetch/s--EbxCAVv4--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://thepracticaldev.s3.amazonaws.com/i/umqi13yq0uiiqycigsps.jpeg)

阶段 0 - *原始数据*是任何格式的输入数据。从网上搜集的 HTMLs，从数据供应商那里得到的大型 SQL 转储，从 200 张 DVD 拷贝的 dBase 文件(真实故事)。出于存档和复制目的，请始终保存此文件。该数据是不可变的，将被写入一次并读取多次。

> 例如:从[scrapethissite.com](https://scrapethissite.com/pages/simple/)收集的国家名称、首都、地区和人口，存储为一个 HTML 文件。

阶段 1 - *一致*数据具有与原始数据相同的信息内容，但采用了具有一致模式的首选格式。您可以协调不一致的列名，纠正缺失的值编码，转换为 CSV，诸如此类。还没有判断清洗。在我们的例子中，一致数据包含一些 UTF-8 编码的 CSV 文件，它们具有有意义的列和表名，通常遵循[整洁数据原则](http://vita.had.co.nz/papers/tidy-data.html)。这种转换不涉及信息损失或只涉及最小的信息损失。

> 示例:UTF 8 编码的单个 CSV 文件，包含列`country_name`、`capital`、`area`、`population`。

Stage 2 - *clean* 数据是数据中信息的最佳表现形式，可以在许多应用程序中重用。这一转换步骤涉及大量的清理、内部和外部一致性检查。可能会丢失一些信息。写了几次，读了许多次，经常被许多用户用于许多不同的项目。当提及已知实体(公司、城市、机构、个人、国家)时，应使用规范的唯一标识符，如国家的[ISO-3166–1 代码](https://datahub.io/core/country-list)。

> 示例:与一致相同，增加了 ISO-3166 国家代码和城市的[地理名称 ID](https://www.geonames.org/) 列。你也可以添加每个首都的地理坐标。

阶段 3 - *派生的*数据通常只包含原始数据中信息的子集，但是被构建为在不同的项目中重用。您可以聚合到每年的频率，只选择列的子集，诸如此类。想想 SELECT，WHERE，GROUP BY 子句。

> 例如:欧洲所有国家。

阶段 4 - *分析样本*包含您分析所需的所有变量定义和样本限制。该数据通常仅用于一个项目。在此阶段，您应该只与其他干净的或派生的数据集进行连接，而不是在此之前。这是由少数用户频繁编写和阅读的。

> 示例:欧洲国家样本与首都城市的人口([来自联合国](https://unstats.un.org/unsd/demographic/products/dyb/City_Page.htm))相结合，因此您可以计算居住在首都的人口比例。

## 如何从一个阶段进展到另一个阶段？

**自动化所有阶段之间的数据清理和转换**。在原始数据和一致数据之间，这通常是最困难的，因为原始数据可能有不同的格式。但是从一致的阶段开始，你真的没有借口不自动化。有没有更好的算法去重复公司名称(在清理阶段)？只是重新运行所有后面的脚本。

**不要跳过一个阶段**。就像悲伤的五个阶段一样，从长远来看，你必须经历所有阶段才能与你的数据保持平静。对于格式非常好的原始数据，您可以直接进行清理，但永远不要跳过任何后续阶段。这源于[模块化思维](https://dev.to/korenmiklos/the-tupperware-approach-to-coding-1g74):把你或其他人以后可以重用的东西分离出来。如果您想对亚洲国家重新进行国家资本分析，该怎么办？如果您编写了一个庞大的脚本来从您的原始数据到分析样本，如果它将被重用，没有。

**加入晚**。尽早将您的城市信息加入国家首都数据集可能很有诱惑力。但是你不知道其他用户需要这些数据做什么。而你在自己的数据还没有足够干净之前，是不想加入的。一个干净的数据应该尽可能接近[第三范式](https://en.wikipedia.org/wiki/Database_normalization#Normal_forms)。

**分享你的中间数据产品**。你所做的所有数据清理可能对其他人也有用。如果可能的话，与其他分析师和研究人员分享你的中间产品。你也可以把它们发布在 [datahub.io](https://datahub.io/) (它有很好的工具来发布自包含的数据包)或者像【zenodo.org】T4 这样的存储库中。即使你不能分享，假装你正在为别人准备你的中间产品。自动化并记录一切。你未来的自己会感谢你。