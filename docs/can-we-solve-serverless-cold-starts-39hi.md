# 我们能解决无服务器冷启动吗？

> 原文：<https://dev.to/byrro/can-we-solve-serverless-cold-starts-39hi>

[![Heating Up Ice](img/c81bb30ca48c153da106fe307a80cb74.png)](https://res.cloudinary.com/practicaldev/image/fetch/s--HViRkjA6--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://thepracticaldev.s3.amazonaws.com/i/e8p8kfb3mn5hztrhh977.jpg)

正如生活中的一切美好事物一样，无服务器也有它的缺点。其中之一就是臭名昭著的“冷启动”。在本文中，我们将讨论它们是什么，什么影响无服务器启动延迟，以及如何在我们的应用程序中减轻其影响。

# 什么是冷启动

冷启动指的是我们的函数在服务特定调用请求时的状态。无服务器功能由一个或多个微容器提供。当一个请求进来时，我们的函数将检查是否有一个容器已经在运行来为调用提供服务。当一个空闲容器已经可用时，我们称之为“热”容器。如果没有现成的容器，这个函数将旋转一个新的，这就是我们所说的“冷启动”。

当调用处于冷状态的函数时，请求将需要额外的时间来完成，因为在启动新容器时会有延迟。这就是冷启动的问题:它们使我们的应用程序响应更慢。在 21 世纪的“即时时代”，这可能是一个大问题。

# 寒冷是如何开始工作的

[![Ice Cubes](img/67920dde4569fdf55a8da16debe07777.png)](https://res.cloudinary.com/practicaldev/image/fetch/s--9v7_2ym5--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://thepracticaldev.s3.amazonaws.com/i/046keevie39wh4ds83wp.jpg)

现在我们知道了什么是“冷启动”，让我们深入了解它们是如何工作的。内部工作可能与你正在使用的服务(AWS Lambda、Azure Functions 等)或开源项目(OpenFaas、Kubeless、OpenWhisk 等)不同，但总的来说，这些原则适用于所有无服务器计算架构。

在一个请求被一个无服务器容器服务后，它通常保持活动和空闲一段时间。容器编排系统将使用其参数来决定是否以及何时关闭容器。这里有一个权衡:保持容器活动将节省启动资源并加速后续请求，但会增加空闲时间成本。AWS Lambda 通常可以让容器存活 30-45 分钟。有时甚至更多(特别是对于运行在 VPCs 内部的 Lambdas)，但这不是一个有文档记录或提交的参数，所以不要盲目相信它。

当容器从冷态启动时，该功能需要:

1.  从外部永久存储中获取包含您的代码的包；
2.  旋转容器；
3.  将您的包代码加载到内存中；
4.  运行函数的处理方法/函数。

完成这些步骤需要一段时间，尤其是第 1 至第 3 项。当一个容器已经变暖时，它会直接跳到#4，这样可以节省很多时间，让我们的应用程序响应更快。

# 什么可以改善启动延迟

[![Heating Up Ice](img/72e02167b6eff56296c8d46173e31c58.png)](https://res.cloudinary.com/practicaldev/image/fetch/s--4hUDC2SD--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://thepracticaldev.s3.amazonaws.com/i/hoatgeadvkwmvfulemc6.jpg)

“冷启动”延迟影响从几百毫秒到几秒或几秒不等。驱动冷启动延迟的主要因素有:

*   **内存大小**:分配给你的函数的内存越多，它启动的速度就越快；
*   **运行时**:通常脚本语言(Python、Ruby、Javascript)在启动时比编译运行时(Java、.NET，c#)；我的意思是，快 100 倍，这是一件大事；
*   **VPC** :在虚拟私有云内运行的功能将遭受额外的延迟，通常需要额外的一两秒钟才能启动；尝试将您的函数设计为在 VPC 之外运行；
*   **代码包大小**:大小越大，旋转一个新容器所需的时间越多，尽管这可能是影响启动延迟的最不重要的因素；

# 如何解决——或减轻——容器启动延迟

我们提出以下 6 个策略来解决或至少减轻容器启动延迟对无服务器应用程序的影响:

*   监控性能并记录相关指标
*   增加内存分配
*   选择更快的运行时
*   将共享数据保存在内存中
*   缩小包装尺寸
*   保留一个预暖函数池
*   使用时间序列预测

### 监控性能并记录相关指标

我们触及了驱动容器启动延迟的基础设施因素，但是我们的代码也是一个主要的贡献者。我们需要不断地监控我们的应用程序的性能，以便识别瓶颈以及是什么导致执行时间的增加或减少。

为了做到这一点，建议总是在函数执行期间记录时间戳，并监视函数调用历史中的持续时间异常值。每当它的性能比预期的差时，就查看日志并确定代码的哪些部分导致了差的性能。

诸如 [AWS X-Ray](https://aws.amazon.com/xray/) 和 [Dashbird](https://dashbird.io) 之类的服务支持这种开箱即用的分析，为您的性能优化之旅节省大量时间。如果您在专业项目的生产中运行无服务器功能，使用这样的服务是必须的。

### 增加内存分配

据观察，分配了更多内存的函数启动新容器的速度更快。如果成本影响对您的用例来说不是问题，请考虑为您需要最佳启动性能的函数分配更多内存。

### 为对启动时间敏感的工作负载选择更快的运行时间

Python 和 Ruby 等脚本语言的性能明显优于编译运行时。崔琰在 AWS Lambda 中对语言启动时间做了一个很棒的比较。Python 是表现最好的，启动时间比 Java、C#和 NodeJS 等其他竞争者快 100 倍。只要有可能，考虑用 Python 这样的轻量级语言编写无服务器函数。尽管 Python 脚本的执行速度较慢(由于其解释的性质)，但减少的启动延迟可能会抵消并提供整体更好的性能(并降低云提供商的费用)。

### 通过加载外部主事件处理函数将共享数据保存在内存中

无服务器函数通常有一个处理器方法/函数作为底层基础设施和我们的代码之间的接口。该函数通常会将事件和上下文作为参数传递给我们的函数，从那里开始，我们的奇迹就发生了。

有趣的是，我们可以让代码在这个方法/函数之外运行。假设每次调用我们的函数时，它都需要导入相同的第三方库，或者从外部持久性存储中获取一个对象。我们可以在调用处理程序方法/函数之前，在处理程序之外做这些事情，而不是在调用处理程序方法/函数之后。

只要容器还活着，在处理程序之外声明和执行的所有东西都将保留在容器的内存中。当它再次被调用(从热状态)时，数据的导入或获取将不需要再次运行，它们可以直接从内存中使用，从而加快代码的执行时间。

这不会加速冷启动，但会减少后续请求的启动时间。总的来说，我们的应用程序会有更好的性能。

### 缩小包装尺寸

当我们为无服务器功能打包代码时，通常会将我们所有的东西都放在压缩文件中，从自述文件到不必要的第三方库文件。在部署到生产中之前清理我们的包是很重要的，删除我们的函数运行中不使用或不需要的所有东西。这将有助于通过减少内部网络延迟来缩短冷启动时间-该功能将获取一个较小的程序包文件。

### 保留一池预热功能

如果您仍然经历难以忍受的冷启动延迟时间，最后一个办法是设置常规作业来保留一个预热功能池。它是这样工作的:

配置您的函数以识别短路的预热调用并快速结束请求，而无需运行整个函数代码。这可以通过向函数传递一个预先确定的事件来实现，比如:{“warm”:true }。当您的函数检测到这个事件参数时，尽可能快地停止执行。

设置一个常规作业(例如 CRON)每隔几分钟调用一次您的函数。分钟数取决于。AWS Lambda 通常让容器存活大约 30-45 分钟，但它会有很大变化。

通过调用该函数，无服务器的底层系统将需要启动一个新的容器，并使其保持活动一段时间。如果有一个预加热的容器，由于最近的加热呼叫，它将保持它一段更长的时间。当一个真正的用户请求您的 API 时，这个容器将用于更快的响应。

Jeremy Dale [开源且有趣的软件包](https://github.com/jeremydaly/lambda-warmer)为了帮助管理 AWS Lambda 的变暖策略，你可能想看看它。[无服务器框架](https://serverless.com/)也有一个[有用插件](https://www.npmjs.com/package/serverless-plugin-warmup)。

当心并发性的影响:如果您只为您的函数保持一个容器活动，并且有两个并发请求进来，其中一个将从热状态得到服务，但是第二个将是冷启动。那是因为只有一个容器是热的，而且一次只能满足一个要求。如果您的应用程序通常服务于多个并发请求，请在预热策略中考虑这一点。

### 看中时间序列预测进行预暖策略

如果您真的担心冷启动延迟，并且您的应用程序负载在并发请求数量上表现出很大的差异，那么您可能想更进一步。您可以使用时间序列预测来预测在每个时间点应该加热多少容器。StatsModels 是一个开源项目，提供了处理时间序列最常用的算法。这里有一个[好教程](https://machinelearningmastery.com/time-series-forecasting-methods-in-python-cheat-sheet/)让你开始。

我们需要的基本上是一个有两个轴的时间序列样本:

1.  一段时间内的一系列间隔(例如，过去 3 个月内的 10 分钟间隔)
2.  函数在该时间间隔内处理的最大并发请求数

我们会定期(例如每 10 分钟)运行时间序列预测，以预测在下一个时间间隔(例如接下来的 10 分钟)内需要多少个集装箱。加热策略将被调整以确保这些数量的容器被预加热。

使用统计预测的一个积极方面是它将返回一个标准差(SD)。考虑到数据和标准差的概率分布，您可以估计预测的置信水平。假设你想在 99%的情况下确定你的预测；你需要预测所需的集装箱数量，然后加上标准偏差，再乘以一个系数。这个因素将取决于数据的分布。例如，如果正态分布，系数将为 2.58。阅读更多关于[置信区间](https://en.wikipedia.org/wiki/Confidence_interval)的内容，以防你想更深入地了解这个话题。

* * *

Renato 是 Dashbird.io 的开发人员，这是一个专门为无服务器环境设计的监控和调试服务。你可以在 [Twitter](https://twitter.com/@byrrorenato) 和 [Medium](https://medium.com/@byrro) 上关注我。