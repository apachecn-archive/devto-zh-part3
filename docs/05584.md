# 卡夫卡和鲁比，一个旁门左道的爱情故事

> 原文：<https://dev.to/appsignal/kafka-and-ruby-a-sidekiq-lovestory-4dm5>

在今天的文章中，我们将从一个不同的角度来讨论性能:我们在堆栈中所做的选择。

通常我们会在我们的 [changelog](https://appsignal.com/changelog) 和博客上写下我们为 AppSignal 发布的变化和功能。但除了这些面向公众的功能，我们还花了很多时间来确保 AppSignal 能够应对流量的增长。

因为我们是开发人员，我们自己也在解决这样的问题，我们认为我们在帮助*你*以及我们的 [APM](https://appsignal.com/) (无耻之徒)方面做得很好🤪).但今天我们利用这一经历来讨论我们自己的堆栈。我们将回顾过去几年中我们自己所做的一个更大的改变，以处理每月数十亿的请求。我们将介绍我们为什么做出这样的选择，以及我们的方法的利与弊。

## 从一个标准的 Rails 设置到更多的定制部件

AppSignal 最初是一个非常标准的 Rails 设置。我们使用了一个 Rails 应用程序，它通过一个 API 端点收集数据，该端点创建 Sidekiq 作业以在后台处理。

过了一段时间，我们用 Rack 中间件替换了 Rails API 以获得一点速度，后来又用 Go web 服务器替换了它，该服务器将 Sidekiq 兼容的作业推送到 Redis。

## App 状态和增量/更新

虽然这种设置在很长一段时间内运行良好，但我们开始遇到数据库跟不上查询量的问题。此时，我们已经处理了数百亿个请求。这样做的主要原因是，每个 Sidekiq 进程需要从数据库中获取整个应用程序的状态，以便增加正确的计数器并更新正确的文档。

我们可以通过数据的本地缓存在一定程度上缓解这种情况，但是由于我们设置的循环性质，这仍然意味着每个服务器都需要有所有数据的完整缓存，因为我们不能确定有效负载最终会在哪个服务器上。我们意识到，随着数据的增长，这种设置在未来将变得不可能。

## 进入卡夫卡

为了寻找更好的方法来处理数据，我们决定使用 Kafka 作为数据处理管道。我们现在在 Kafka *处理器*中聚合指标，而不是在数据库中聚合指标。我们的目标是我们的 Kafka 管道从不查询数据库，直到聚集的数据被刷新。这使得每个有效负载的查询数量从多达 10 次读取和写入减少到管道末端的一次写入。

我们为每个 Kafka 消息指定一个密钥，Kafka 保证相同的密钥最终出现在相同的分区上，由相同的服务器使用。我们使用应用程序的 ID 作为消息的密钥，这意味着我们只需缓存服务器从 Kafka 接收的应用程序的数据，而不是所有应用程序，而不是服务器上所有客户的缓存。

卡夫卡是一个伟大的系统，我们已经在过去的两年里进行了迁移。目前，几乎所有的处理都是通过 Kafka 在 Rust 中完成的，但仍然有一些事情在 Ruby 中更容易完成，例如发送通知和其他数据库繁重的任务。这意味着我们需要某种方式将数据从 Kafka 传输到我们的 Rails 堆栈。

## 连接卡夫卡和 Ruby/Rails

当我们开始这种过渡时，有几个 Kafka Ruby gems，但没有一个能与 Kafka 的最新版本(当时是 0.10.x)一起工作，大多数都没有维护。

我们看着写我们自己的宝石([，我们最终做了](https://github.com/appsignal/rdkafka-ruby))。我们将在另一篇文章中对此进行更多的讨论。但是有一个好的司机只是要求的一部分。我们还需要一个系统来消费数据，执行 Ruby 中的任务，并在旧的工作线程崩溃时产生新的工作线程。

最终我们想出了一个不同的解决方案。我们的 Kafka 堆栈是在 Rust 中构建的，我们编写了一个小的二进制文件，它使用了一个`sidekiq_out`主题，并在 Redis 中创建了 Sidekiq 兼容的作业。这样我们就可以在我们的工作机器上部署这个二进制文件，它会像在 Rails 内部一样向 Sidekiq 提供新的任务。

二进制文件有一些选项，比如限制 Redis 中的数据量，以停止使用 Kafka 主题，直到阈值被清除。这样，如果有积压，Kafka 的所有数据都不会在 Redis 的工人内存中结束。

从 Ruby 的角度来看，Rails 产生的工作和 Kafka 产生的工作没有任何区别。它允许我们制作新工人的原型，这些工人从 Kafka 获取数据并在 Rails 中处理这些数据——发送通知和更新数据库——而无需了解 Kafka 的任何信息。

这使得向 Kafka 的迁移变得更加容易，因为我们可以在 Kafka 之间来回切换，而不必部署新的 Ruby 代码。它还使测试变得非常简单，因为您可以轻松地在测试套件中生成供 Ruby 使用的作业，而不必在本地设置整个 Kafka 堆栈。

我们使用 [Protobuf](https://developers.google.com/protocol-buffers/) 来定义我们所有的(内部)消息，这样我们可以非常确定如果测试通过，工人将正确地处理来自 Kafka 的作业。

最终，这个解决方案为我们节省了大量的时间和精力，也让我们的 Ruby 团队的生活变得简单了许多。

## 利弊

与所有事情一样，这种设置也有一些优点和缺点:

优点:

*   无需更改 Ruby，API 兼容
*   易于部署和恢复
*   在卡夫卡和鲁比之间轻松切换
*   Redis 在使用 limiter 时不会被消息过载，节省了服务器上的内存，而是将消息保存在 Kafka 中。
*   由于键控消息，水平扩展导致每个服务器上的缓存更小。

缺点:

*   仍然存在这样的问题，即每个 Sidekiq 线程都需要从服务器使用的分区中访问应用程序的所有数据的缓存。(例如 Memcache)。
*   在服务器上运行的独立进程
*   rust 处理器在消息被刷新到 Redis 时提交消息偏移量，这意味着它保证在 Redis 中，但不能保证消息被 Ruby 处理，这意味着在服务器崩溃的情况下，一些在 Redis 中但未被处理的消息有可能未被处理。

## Sidekiq 和卡夫卡

在将我们的处理流程迁移到 Kafka 时，使用 Sidekiq 帮了我们很大的忙。我们现在几乎完全摆脱了 Sidekiq，直接通过我们的 Kafka 驱动程序处理一切，但那是另一篇文章了。

今天到此为止。我们希望您喜欢这个关于性能和可伸缩性的观点，以及我们扩展 AppSignal 的经验。并关注我们关注下一集关于卡夫卡的内容何时出版。