# 坞站和坞站组成

> 原文:# t0]https://dev . to/ylganathan/docker and docker-compound-415 I

为了理解 docker，我们必须回到过去，研究容器的演变以及我们是如何走到今天的！

## [](#what-is-a-container)什么是容器？

从 docker 网站

> “容器是一种将软件打包成可以在共享操作系统上独立运行的格式的方法。与虚拟机不同，容器不捆绑完整的操作系统，只需要使软件工作所需的库和设置。这有助于构建高效、轻量、独立的系统，并保证无论软件部署在哪里，它都将始终运行相同的软件。”

让我们打开它一点

*   早在 90 年代末，VMWare 就引入了在同一硬件上运行多个操作系统的概念。
*   在 21 世纪后期，引入了内核级命名空间，允许共享的全局资源(如网络和磁盘)通过命名空间隔离。
*   在 2010 年代早期，容器化诞生了，它在操作系统级别实现了虚拟化，并添加了共享库/bin。这也意味着我们不能在同一个主机上运行依赖于不同操作系统的两个容器，除非我们使用一个 VM。
*   名称空间是容器背后真正的魔力。原理来自 linux 容器，docker 实现了自己的 OCI 运行时，名为[runc](https://github.com/opencontainers/runc)T0】

## [](#advantages-of-using-containers)使用容器的优点

1.  速度

    *   执行速度——因为容器使用底层的主机操作系统，所以我们获得的速度接近在主机操作系统上运行的进程。
    *   启动速度-集装箱可以在不到一秒钟内启动。它们非常模块化，可以在需要时与主机操作系统共享底层库/库。
    *   操作速度——容器支持更快的应用程序迭代。创建一个包含新代码变更的容器，并通过管道将其转移到生产环境中，开销会更少。
2.  一致性

    *   一次创建一个映像，并在任何地方使用它。用于运行测试的同一映像将用于生产中。这避免了我的机器出现问题。
    *   不仅仅是生产。容器有助于一致地运行测试。曾经有过这样的场景:所有测试都在您的机器上通过，但是 CI 没有通过您的测试？。
3.  可量测性

    *   我们可以精确地指定单个容器可以消耗多少资源(CPU 和内存)。通过了解可用的资源，容器可以被密集地打包以最小化 CPU 和内存的浪费。在缩放实例之前，缩放一个主机中的容器。
4.  灵活性

    *   容器是便携的。在某种程度上(只要主机运行某种形式的 linux 或 linux vm)。
    *   你可以很快地把一个集装箱从一台机器转移到另一台机器上。假设在修补主机操作系统中的安全漏洞时出现了问题，我们只需将容器移动到不同的主机上，就可以非常快速地恢复服务。

## [](#enter-docker)输入 Docker

### [](#docker-as-a-company)作为公司的码头工人

1.  2013 年，Docker 创建了第一个容器平台。
2.  2015 年，Docker 创建了[开放容器倡议](opencontainers.org)——围绕容器映像和运行时规范的治理结构。他们还向 OCI 捐赠了第一个运行时。docker 和许多其他平台使用的当前运行时是用 golang 编写的 runC。

### [](#docker-runtimedaemonengine)Docker 运行时/守护进程/引擎

1.  Docker 引擎是为 linux 打造的。
2.  Docker for Mac 使用 HyperKit 运行轻量级 Alpine Linux 虚拟机。
3.  Docker 与微软合作，创建了 Windows 10 或 Windows server 2016 中可用的 Windows OCI 运行时。

### [](#docker-cli)坞站 Cli

1.  Docker cli 命令看起来与 git 命令非常相似。他们中的许多人也有相同的背景。
    1.  `git pull`将源从原点获取到本地
    2.  `docker pull <image>`将从远程注册表获取 docker 镜像到本地
2.  Docker 遵循客户端服务器模型，因此 cli 可以连接到本地 docker 服务器或远程服务器

## [](#docker-images)Docker 图片

> 图像是一个只读模板，包含创建 Docker 容器的说明。通常，一个图像基于另一个图像，并进行一些额外的定制。例如，我们可以构建一个基于 ubuntu 映像的映像，但是安装 Apache web 服务器和您的应用程序，以及运行您的应用程序所需的配置细节。

我们需要一个 **Dockerfile** 来创建一个图像。让我们看一个例子。这是一个使用 gunicorn
运行 python flask 应用程序的图像

```
FROM python:3.7.3-stretch

ADD . /code
WORKDIR /code

COPY Pipfile Pipfile.lock /code/

RUN apt-get update

RUN apt-get install postgresql postgresql-client --yes && \
    apt-get -qy install netcat && \
    pip install --upgrade pip setuptools wheel &&\
    pip install --upgrade pipenv && \
    pipenv install --dev --system --ignore-pipfile

CMD ["/usr/local/bin/gunicorn", "--config", "wsgi.config", "coach_desk:create_app('development')"] 
```

### [](#images-are-a-collection-of-immutable-layers)图像是不可变图层的集合。

上面 docker 文件中的每条指令都在映像中创建一个层。当我们改变 Dockerfile 文件并重建图像时，只有那些已经改变的层被重建。与其他虚拟化技术相比，这是映像如此轻便、小巧和快速的部分原因。

### [](#images-can-also-be-built-on-top-of-other-images)图像也可以建立在其他图像之上。

dockerfile 文件中的第一行是`FROM`，它指定了构建当前图像的图像。让我们看看用于创建 python 图像的`Dockerfile`。这个图像是从`buildpack-deps:stretch`构建的，它提供了支持任何语言的所有基本工具。

```
FROM buildpack-deps:stretch

# ensure local python is preferred over distribution python
ENV PATH /usr/local/bin:$PATH

# http://bugs.python.org/issue19846
# > At the moment, setting "LANG=C" on a Linux system *fundamentally breaks Python 3*, and that's not OK.
ENV LANG C.UTF-8

# extra dependencies (over what buildpack-deps already includes)
RUN apt-get update && apt-get install -y --no-install-recommends \❗
        tk-dev \
        uuid-dev \
    && rm -rf /var/lib/apt/lists/*

ENV GPG_KEY 0D96DF4D4110E5C43FBFB17F2D347EA6AA65421D

ENV PYTHON_VERSION 3.7.3
... 
```

`buildpack-deps:stretch`是从`buildpack-deps:stretch-scm`开始建造的，而`buildpack-deps:stretch-scm`是从`buildpack-deps:stretch-curl`开始建造的，而`debian:stretch`是从零开始建造的。

```
FROM scratch
ADD rootfs.tar.xz /
CMD ["bash"] 
```

如果我有 1000 个 docker 文件都是从`python:3.7.3-stretch`开始构建的，那么相关的层不会被下载 1000 次，而只会被下载一次。容器也是如此，当我们运行一个 python 容器 1000 次时，python 只安装一次就可以重用。

## [](#docker-registry)码头登记处

注册表是存储所有图像的地方。当我们安装 docker 时，我们有一个本地注册表，其中存储了我们创建的所有图像。
尝试`docker images`列出您本地注册表中当前的所有图像
[`docker hub`](https://hub.docker.com/) 是一个公共存储库，拥有超过 100，000 张图像。这将是寻找预构建图像的第一个地方，我们可以直接使用或用作基础图像来构建。

我们可以使用`docker push`和`docker pull`命令将图像从本地移动到远程。除非我们明确指定，否则默认的远程注册表是 docker hub。在 Peaksware，我们使用 Amazon ECR 来存储我们的生产 docker 图像。

## [](#docker-compose)复合坞站

引入了 Compose，因此我们不必手动构建和启动每个容器。Compose 是一个定义和运行多容器 Docker 应用程序的工具。Compose 最初是为了开发和测试目的而创建的。最近发布 Docker 已经将 compose yml 用于创建 docker 群组。

### [](#using-docker-compose-for-a-real-application)使用 docker 编写一个实际应用程序

我们团队工作的一个微服务需要正确的 postgres 数据库以及所有的迁移和 aws cli 设置，以便在开发人员机器上本地运行该服务。这项服务相当新，后端一直在发展，我们需要一种快速的方法来为依赖这项服务的前端开发人员提供服务。Docker compose 派上了用场，下面的合成文件将旋转两个容器

1.  Python docker 并安装所有依赖项，然后启动 web 服务器
2.  Postgres 数据库

```
version: '3.7'

services:
  web:
    build:
      context: ..
      dockerfile: df.dev.Dockerfile

    environment:
      - DB_URI=postgres://postgres:postgres@db/idea_box

    command: bash -c  "flask migrate && flask run -p 5000 -h 0.0.0.0"
    ports:
      - 5000:5000
    links:
      - db
    volumes:
      - ../:/code

  db:
    image: postgres:10.1
    environment:
      POSTGRES_DB: idea_box 
```

我们可以使用`links`来指定依赖关系。web 服务容器将一直等到 db 容器启动，然后才执行 entry 命令`bash -c "flask migrate && flask run -p 5000 -h 0.0.0.0"`，该命令将运行迁移并启动 flask 服务器。

如果有人想运行这个服务，他们不必安装 python 或 flask 或 postgres，而是由开发人员运行`docker-compose -f docker-compose.yml up`并等待 api 在 localhost:5000 可用

### [](#adding-real-complexity)增加真实的复杂性

当您的服务如此简单时，这非常有用。实际上，我们必须添加一个队列和 lambda 函数来处理队列并将消息发送到不同的服务。不幸的是，我们发现了模拟 AWS 服务的 [`localstack`](https://github.com/localstack/localstack) 。

我们可以使用 [localstack](https://github.com/localstack/localstack) 在本地启动 SQS 实例，并使用通过 localstack 容器中的 entrypoint 调用的 init shell 脚本创建一个队列。

这仍然不能代表完整的服务。我们仍然需要一个本地 lambda 函数来读取队列并将消息推送到另一个服务。这就是我发现在 docker compose 中设置整个服务所付出的努力超过了收益的地方。

```
version: '3.7'

services:
  web:
    build:
      context: ..
      dockerfile: .df.dev.Dockerfile

    environment:
      - DB_URI=postgres://postgres:postgres@db/coach_desk
      - AWS_ACCESS_KEY_ID=foo
      - AWS_SECRET_ACCESS_KEY=bar
      - AWS_ENDPOINT=http://aws:4576

    command: bash -c  "flask migrate && flask run -p 5000 -h 0.0.0.0"
    ports:
      - 5000:5000
    links:
      - db
      - aws
    volumes:
      - ../:/code

  db:
    image: postgres:10.1
    environment:
      POSTGRES_DB: coach_desk

  aws:
    image: localstack/localstack
    ports:
      - 4576:4576
      - 8080:8080
    environment:
      - SERVICES=sqs
      - DEBUG=True
    volumes:
      - ./localstack:/docker-entrypoint-initaws.d 
```

尽管在实际服务中使用 docker compose 有些复杂，但我还是建议尝试一下，看看它是否适合您的团队。我很想听听你/你的团队如何使用 docker 进行开发和测试。

## [](#developing-with-docker)用 Docker 开发

*   没有痛苦的开发者机器设置。有了 compose，任何人都可以非常快速地启动服务，而不必安装他们永远不会使用的所有依赖项。

*   一致的结果-从开发到生产。构建是可重复的、可靠的，并且经过测试，在生产中完全按照预期运行。

*   加速测试——我们有需要测试数据库的测试，我们有在每个测试/测试组之后的拆卸来清理数据库。我正在为我们的项目研究在多个容器中运行数据库的并行测试方法。

*   代码审查可以是无痛的——每个开发人员可以在他们的代码审查中附加一个图像，这样审查人员就可以快速地进行审查，而不必中断他们正在做的事情并测试不同版本的代码。

*   快速修复可以很快——当开发人员发现 bug 时，他们可以在开发环境中修复它们，并将它们重新部署到测试环境中进行测试和验证。测试完成后，向客户提供修复就像将更新的映像推送到生产环境中一样简单。