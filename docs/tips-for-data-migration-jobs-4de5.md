# 数据迁移作业提示

> 原文：<https://dev.to/hazelwood69/tips-for-data-migration-jobs-4de5>

数据迁移在 20 年前是一个问题，现在依然如此。很明显那里有问题。

我最近经历了一次地狱般的迁移，我相信这就是我写这篇文章的动机。

正如 vey well 在他的文章[中指出的](https://dev.to/mscccc/high-traffic-app-that-cant-take-downtime---data-migration-450d) [Mike Coutermarsh](https://dev.to/mscccc) 高流量应用不能停机

数据迁移通常遵循以下方法:

1.  创建新表格
2.  写入两个表
3.  复制数据的后台作业
4.  从新表中读取
5.  删除旧表

每一步都是一次释放...

嗯，这似乎是一个非常好的方法，但我现在可以告诉你，它的成功将取决于你的后台工作如何管理这个数据迁移。

因此，我将解释我所认为的良好的生产就绪数据迁移策略，并希望您在下次迁移时采纳其中的一些技巧。

首先，如果您想通过运行一些 sql 查询、导入/导出工具或 bash 脚本将数据转储到新的数据库/表中来实现这一点，那么肯定您的迁移失败了。
采用这种方法会让你陷入这样的境地:

*   您可能会耗尽资源。磁盘、内存等...
*   在生产中运行之前，您可能已经测试过它，但是，您有多大把握用于测试它的数据与生产中的数据相匹配？想想你的测试数据库没有的极限情况。
*   您可能正在进行错误的数据转换，直到最后才意识到
*   在执行 sql 查询以迁移数据的过程中，您的数据库可能会经历服务降级。

这些都会导致整个系统运行缓慢，甚至部分或全部停机。如果发生这种情况，您的用户将无法与您的系统进行交互。那么，为什么要冒险采用这种方法呢？

我认为进行任何迁移工作的更好方法包括:

*   了解您的数据需要如何迁移。这是关键。似乎显而易见，但这经常失败。
*   知道你实际上要移动多少数据。这似乎也是显而易见的，但大多数时候是不确定的。
*   定义完整迁移的时间框架。迁移需要时间，不要操之过急。
*   定义迁移的速率/速度。如果你愿意，可以遵循线性或指数比率。
*   将迁移过程作为无服务器作业运行。不要为了一个单一的任务浪费资源，任何 k8s job/cronjob，lambda function，你喜欢的 whatelseserverless 都可以做到。
*   编写此作业时，请考虑:
    *   可配置性:将作业设计为可以在给定数量的要立即迁移的项目上进行配置。使用前(100)条记录或所有记录的 1%|5%|10%或选择从日期 a 到日期 b 的记录，等等...使用任何能分割数据的东西。
    *   可追溯性:从源到目的地跟踪迁移的记录。数据迁移时添加一个 key:value `datamigrated: true`。或者将 key:id 存储在一个文件或临时表中，这样您就不必返回到那些记录中
    *   自我修复:从失败中恢复。如果该流程能够从失败中恢复并自己重新开始工作，您的待命同事将会非常感激。
*   计划并执行迁移测试:第一次运行时，对数据子集进行测试。如果出了问题至少不会影响所有的数据。
*   拿一些指标来说，比如 start_timestamp 和 finish_timestamp，如果你不使用它们，其他人可以使用它们。
*   评估测试是否按预期进行，数据是否符合迁移标准。
*   以相同的速度重复，或者增加要在这个迭代中迁移的数据块，直到完成为止。

祝你好运，祝你移民愉快。

请在评论中告诉我你对此的看法，因为这是我在 dev.to 的第一篇帖子