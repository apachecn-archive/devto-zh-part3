# 为 SEO 目标重新编码 HTML？

> 原文:[https://dev . to/Nicholas Davis 85/re-coding-html-for-SEO-goals-5e 64](https://dev.to/nicholasdavis85/re-coding-html-for-seo-goals-5e64)

## SEO 为什么需要 HTML 知识？

如果有一件事，我已经看到，因为我开始做搜索引擎优化咨询服务的事实是，许多人完全忽略了他们的网站的技术方面。事实上，即使是基于 CMS 的，在线门户网站也应该有相关知识的人来关注元标题、描述以及关键字应该放在网站后端的什么位置。请记住，这只是基本的东西，但你不会想象有多少次做得很差。

## 微数据狂言

对于我们这些最近接受了 SEO 训练的 web 开发人员来说，处理微数据是相当痛苦的。尽管谷歌最近决定拥抱 Schema.org 文化，但他们对结构化数据的实现仅限于 JSON-LD 片段，这极大地限制了我们的编码优化。不要误解我的意思，当涉及到结构化数据时，结果才是真正重要的，但谷歌的政策应该更新，特别是在他们的爬行过程中。

## 爬行预算

如果你是一个 web 开发人员，正在和一个想要 SEO 的客户一起工作，你肯定会在 Javascript 和所有针对网站抓取预算的东西上遇到一些问题。这一点在许多采访、网络研讨会、Reddit 的 AMA 和公开演讲中都提到过:
**Googlebot 很老了，它的发展速度非常缓慢**。据说，事实上，机器人正在使用 Chrome 41 来抓取网站，因此所有较新的语法，如 ES6，都只得到部分支持。最新版本的 Chrome 64 应该有助于让机器人跟上
的步伐，但没有人知道它何时会发布并实施到爬行过程中。记住这一点，为了从 SEO 的角度了解你的 JS 部分的表现，采取相应的行动是很重要的，特别是如果你正在经营一家以 JS 非常多而闻名的电子商务商店。我最近与曼彻斯特目前最大的搜索引擎优化代理公司合作，以优化他们的整个后端，让我知道你的想法！

## 速度神话

好吧，让我们把它砍掉。HTML 和 CSS 不会影响网站的加载速度。Javascript 可以。就是这样。非常简单易懂，原因如下。鉴于 Googlebot 爬行过程是基于“基于维基百科”的页面的事实，很容易理解这两个部分是如何以及为什么首先被爬行和索引的，其余的在上面的段落中解释。

## 最后

看看你网站的后端。停止为你的 CMS(特别是 WP)使用[简单编辑器](https://www.smashingmagazine.com/2018/05/things-designers-should-know-about-seo-2018/),因为它们用大量的 JS 变量污染了你的网站，影响了抓取预算和网站速度。优化你的 HTML 和 CSS 和 SEO-wise，你应该没问题(从技术角度来看)。