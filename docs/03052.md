# 如何为机器学习收集数据

> 原文:[https://dev . to/bugfenderapp/how-to-gather-data-for-machine-learning-fkn](https://dev.to/bugfenderapp/how-to-gather-data-for-machine-learning-fkn)

除非你过去几个月一直住在一个山洞里(一个有足够 WiFi 覆盖的山洞，可以到达我们的博客)，否则你肯定听说过机器学习。如果你是一名开发人员，你可能会感兴趣。

不需要详细指令就能解决问题的机器学习算法是这个星球上最令人兴奋的技术之一。自从我开始写这篇文章以来，[脸书](https://venturebeat.com/2019/05/01/facebook-launches-machine-learning-experimentation-tool-ax/)和[微软](https://techcrunch.com/2019/05/02/microsoft-makes-a-push-to-simplify-machine-learning/)已经宣布了他们自己的机器学习计划的主要内容。

但是机器学习被深深地误解了——不仅仅是那些认为这是机器人可怕崛起的黎明的人。在本文中，我们将通过切入其核心来揭开这个概念的神秘面纱:我们为我们的机器学习算法收集数据的方式，遵循一个明确定义的过程。

在这本全面介绍机器学习的书中，我们将为您清晰地解释用于训练和测试机器学习模型的过程，并展示您在各个阶段如何需要不同的数据。不过不用担心，不会太专业。我们改天再上数学课。

## [](#a-general-approach-to-datagathering)**数据收集的一般方法**

机器学习算法需要大量数据才能发挥作用。当处理数百万甚至数十亿的图像或记录时，真的很难找出到底是什么让一个算法表现糟糕。

因此，在编辑数据时，仅仅收集大量信息、将其输入模型并期望得到好的结果是不够的。这个过程需要更加精细地调整。

一般来说，最好遵循一系列迭代阶段，直到你对结果满意为止。该过程应该像这样运行:

1.  选择您的数据分布
2.  将数据分割成数据集
3.  训练模型

## [](#selecting-data-distributions-in-machine-learning)**在机器学习中选择数据分布**

第一步要求我们考虑谁将与我们的模型交互，以及它将处理的各种数据。最好用几个例子来解释，说明当我们*不*考虑这一点时会发生什么。

假设您正在构建一个图像识别模型，为一家在线商店自动标记家具项目。为了训练模型，你从各种制造商的目录中收集了一堆图像，这些图像是具有共同属性(如距离和角度)的专业照片。

然而，在生产中，你让用户从他们的手机上传他们自己的图像。很有可能这些照片质量不高，模糊不清，光线不好，或者以专业摄影师不会使用的不寻常的角度取景。

该系统的性能可能很差，因为用于训练和生产的图像来自两个明显不同的发行版。

[![](../Images/8fda2132051d674ef4e97bdb9ee77e4f.png)T2】](https://res.cloudinary.com/practicaldev/image/fetch/s--CaaaAkTA--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://lh5.googleusercontent.com/-lOlIDUOE02F0qgwR4MhmcJ1Nwdbwlx3PDMrTwDLHH7JkvM8uWi2FFT-0lkdFzLT60APTB7AJYoSwJOGkGyiEp2vCVg259sMtLiPfvH_q_TOu3XHunXi4dyj7goTMlH3cb-_0DUH)

*描述:在这里你可以看到训练中使用的专业照片和真实用户拍摄的劣质照片之间的区别。*

另一个例子:你需要为一个在线图书推荐引擎训练一个模型，但是你相信你的用户群在年龄和性别上是均匀分布的。后来才发现，70%实际上是年轻女性。所以你最终用那些实际上不会使用它的人的数据来训练这个模型。

因此，在收集数据时，重要的是首先要准确定义系统将如何应用，并确保我们用来训练模型的数据能够很好地代表它将在发布到市场时处理的数据。

## [](#creating-machine-learning-datasets)**创建机器学习数据集**

好了，现在我们准备考虑打破我们的想法。因此，让我们用另一个例子来深入探讨这个问题(很抱歉案例研究过多，但这是理解这一点的最佳方式)。

让我们想象一下，我们正在训练某人识别猫和狗之间的区别。我们会给他们看数千张不同类型和品种的猫和狗的照片。

但是，我们如何测试它们以确保所有这些图像都被理解了呢？如果我们给他们看他们已经看过的图像，他们也许能够凭记忆认出它们。所以我们需要给他们看一组新的图像，来证明他们可以把他们的知识应用到新的环境中，并且在没有帮助的情况下给出正确的答案。

机器学习也是同样的原理。我们不希望我们的模型只识别图像，或记录，它一直在训练；这个问题被称为“过度拟合”,不幸的是这种现象非常普遍。当机器学习模型被要求回忆训练中的一个项目时，它们通常表现出色，但离开舒适区时就不那么好了。

因此，在训练我们的机器学习模型时，我们需要创建三个不同的数据集，用于**训练**、**验证**和**测试**。

### [](#the-training-stage)**训练阶段**

自然，我们希望模型在训练结束时尽可能多才多艺，因此训练集覆盖广泛的图像和记录非常重要。但是请记住，我们不需要模型在训练结束时 100%准确。我们只需要将误差保持在最低限度。

在这一点上，有必要引入“成本函数”，这是一个在机器学习开发者中广泛使用的概念。成本函数是模型预测和“正确答案”之间的可变性的度量。成本函数越高，模型的表现越差，尽管还有其他因素要考虑，如反应速度或记忆功能。

(我们可以写更多关于成本函数的内容，但我们不想占用太多时间。这里有一篇关于它的好文章。

### [](#validation-stage)**验证阶段**

一旦我们对我们的成本函数感到满意，并且我们准备好离开培训，就该开始**验证阶段**了。这有点像模拟考试，让模型接受新的和不寻常的数据，没有任何及格-不及格的压力。

使用验证结果，我们可以对模型进行任何必要的调整，或者在不同的版本之间进行选择。与在两个阶段都达到 80%准确率的模型相比，在训练阶段达到 100%准确率但在验证阶段只有 50%准确率的模型不太可能被选中，因为第二个选项更能面对不寻常的情况。

虽然我们不需要在验证阶段给模型提供像在训练期间收到的那么多的数据，但是所有的数据都必须是新的。如果我们循环使用模型被训练过的图像，它会破坏整个对象。

### [](#testing-stage)**测试阶段**

我们听到你问，为什么我们需要第三阶段？验证阶段还不够测试吗？嗯，如果验证阶段足够长且足够严格，模型最终可能会过拟合。它可以学习每个问题的答案。

因此，我们需要第三个数据集，其目标是一劳永逸地定义模型的性能。如果我们在这一盘得到一个不好的结果，我们还不如从头开始。

同样，测试集必须是全新的，没有来自验证集或原始训练集的重复。

关于如何划分你的三个机器学习数据集，没有具体的规则。不过，不出所料，大多数数据通常用于训练——在 80%到 95%之间。其余的在验证和测试集之间平均分配，如下图所示。然而，最终还是要由每个团队通过反复试验来找到他们自己的比率。

[![](../Images/29aa7ae0f68efae86dae443d3c290501.png)T2】](https://res.cloudinary.com/practicaldev/image/fetch/s--HoKa_KSB--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://d2b8vdvorf6w8g.cloudfront.net/wp-content/uploads/2019/05/Dataset-breakdown.jpg)

## [](#training-a-model)**训练一个模特**

好了，现在我们已经准备好了数据，让我们进入培训过程。

数据收集和一般模型训练是一个迭代过程，这意味着我们可能需要重新审视我们在收集数据时所做的决策。该过程包括**数据预处理**、**模型训练**和**参数整定**。

### [](#data-preprocessing)**数据预处理**

输入机器学习模型的数据需要进行转换，然后才能用于训练。

一方面，机器学习模型期望它们的输入具有给定的格式，这通常与你找到数据的格式不同。

另一方面，模型所做的是学习和评估成本函数。他们通过在训练期间最小化函数的误差来做到这一点。在数学中，这被称为“优化问题”，数据的某些特征会影响计算机找到解决方案的速度；最大值或最小值。

预处理过程中使用的数据清理技术的一些例子包括归一化、裁剪或宁滨。下面的[链接](https://developers.google.com/machine-learning/crash-course/representation/cleaning-data)解释这些概念。

### [](#model-training)**模特培训**

训练是如何工作的超出了本文的范围，但是你可以在这里找到更多关于它的信息，也可以在这篇[文章](https://www.tensorflow.org/js/guide/train_models)中获得如何使用 TensorFlow 框架完成训练的实用视图。

理解它对于开发新模型和调整参数是必不可少的，但是一旦完成了这些工作，就会有一些框架将所有这些从我们这里抽象出来。

一个给定的框架将提供一个误差测量，描述模型在最小化成本函数方面的性能。开发人员将需要测试模型，调整其超参数，并继续迭代。

### [](#parameter-tuning)**参数整定**

这一步是训练过程的最后阶段，对任何机器学习项目都至关重要。它包括意识到哪里出了问题，并对需要修改的参数进行有根据的猜测。

这可能会变得非常复杂，但这里有两个非常简单的例子，说明我们在这个阶段可能会修改什么。

如果我们训练我们的模型根据各种气象参数预测明天是否会下雨，我们发现模型有 80%的时间是错误的，我们需要找出原因。一个可能是我们没有足够的记录。在这种情况下，我们将收集更多的信息并再次训练。

或者，如果我们看到模型足够准确，但花费了惊人的长时间来训练，我们可能会考虑调整[学习速率](https://developers.google.com/machine-learning/crash-course/reducing-loss/learning-rate)，这是一个控制优化算法向解决方案前进的速度的参数。

这些只是简单的例子，还有很多，但是我们希望你明白这一点。

## [](#just-one-more-thing)**还有一件事……**

好了，我们对机器学习的介绍到此结束。希望您已经深入了解了数据收集过程的基本原则，并收集了一些对以后有用的见解。

然而，在我们走之前，我们觉得应该提一下我们自己的产品 Bugfender，以及它如何在数据收集过程中提供帮助。

当您的模型采用用户在与系统交互时生成的大量信息时，Bugfender 确实可以帮助您收集机器学习数据。Bugfender 的“标签”可以让你在同一类别下关联日志，你可以用它来创建不同的数据集，或者简单地帮助你以一种方便的方式组织你的训练样本。我们期待在以后的系列中告诉您更多信息。