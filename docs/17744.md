# Ghost 文件描述符接管我的机器。

> 原文：<https://dev.to/captainsafia/ghost-file-descriptors-take-over-my-machine-3ga6>

因此，在另一篇博文中，我开始解释我在构建一个 lerna repo 时遇到的这个问题。这个问题与我的系统上有太多打开的文件描述符有关。当我再次运行这个命令时，它消失了，所以我耸耸肩，什么也没想。

哦，我错了！！！

我暂时没有遇到这个问题，但是最近我在运行一个电子应用程序的 Webpack 构建时遇到了同样的问题。这次我起了疑心。我决定采纳网上提到的一些资源的建议，并使用下面的命令增加我的机器上允许的文件描述符的数量。

```
$ ulimit -n 8192 
```

这应该足够了。对吗？不对！我不断得到这些错误。所以我决定运行另一个命令来计算我的机器上有多少打开的文件描述符。

```
$ lsof | wc -l
   24940 
```

嗯。什么？这似乎是一个荒谬的文件描述符打开的数量。哪些进程正在打开所有这些文件描述符？我决定将`lsof`的输出捕获到一个我可以查看的文件中。

```
$ lsof > fes.txt 
```

我打开文件，开始检查有没有可疑的地方。我注意到的第一件事是 Python 进程打开了大量的文件描述符，大约有 12，662 个。更可疑的是，文件描述符来自 Python 3.6 的 Anaconda 安装下的资源。

```
python3.6  4392 captainsafia  txt       REG                1,4     34284 8596243939 /Users/captainsafia/anaconda3/lib/python3.6/lib-dynload/zlib.cpython-36m-darwin.so.c~ 
```

这有什么奇怪的？因为那天早上我已经卸载了 Anaconda。我遇到了一些不相关的问题，决定用核武器摧毁它。我遵循网站上列出的卸载说明。看起来我之前运行的一个进程的文件描述符没有被清除。事实上，进程 ID 为 4392 的进程不再在我的机器上运行。

所以，我有成千上万个从不存在的进程中运行的 ghost 文件描述符。这很奇怪。这是不可能的。如果一个进程被终止，它打开的文件描述符应该被正确关闭。

现在，这里有一件事需要注意，我最近一直在写一些代码，这些代码产生和关闭与 Jupyter 内核相关的进程。也许是我关机代码中的错误导致了这些问题？

这些文件描述符仍然存在，这看起来真的很奇怪。几个小时前，我重启了我的机器。那不应该已经清除他们了吗？无论如何，我决定让它重新启动。

```
$ lsof | wc -l
    3232 
```

瞧，我的机器上打开的文件描述符的数量更合理了。我继续为我正在工作的电子应用程序初始化构建。这次运行很顺利，我的机器上没有打开过多的文件描述符。我决定再做一件事。

还记得我跟你说过的错误代码吗？我决定对这些代码进行测试。如果与正确关闭正在运行的进程相关的错误没有得到解决，我应该会看到类似的行为。

测试运行顺利，没有任何可疑的事情发生。

我仍然很困惑，为什么我的系统上有这么多打开的文件描述符，却没有与之相关联的进程？我写的代码是用 Node 写的。它使用`process.kill`终止进程，并使用[销毁](https://nodejs.org/api/stream.html#stream_writable_destroy_error)方法关闭与进程相关的标准 I/O 流。

我还在清理关闭代码。在这种情况下，要正确关闭，需要做很多事情。我会继续解决这个问题，等我想通了更多的事情，我会再写一篇博文。

您是否遇到过类似的问题，文件描述符在进程退出时没有被清除？请在评论中告诉我！