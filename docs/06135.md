# 自动编码器:深度学习与 TensorFlow 的热切执行

> 原文:[https://dev . to/striking loo/auto encoders-deep-learning-with-tensor flow-s-eager-API-2522](https://dev.to/strikingloo/autoencoders-deep-learning-with-tensorflow-s-eager-api-2522)

深度学习在过去几年中彻底改变了机器学习场景。我们能把它应用到图像压缩中吗？深度学习算法重建小猫照片的能力有多强？什么是自动编码器？

今天我们将找到所有这些问题的答案。

## [](#image-compression-all-about-the-patterns)图像压缩:关于图案的一切

我之前讲过[无监督学习](http://www.datastuff.tech/machine-learning/k-means-clustering-unsupervised-learning-for-recommender-systems/):应用机器学习在**未标记数据**中发现**模式**。

在图像压缩的情况下，假设大多数图像是**而不是完全随机的**是很有意义的。

用更恰当的话来说，可以有把握地假设大多数图像并不完全由**噪音**(就像你打开一台旧电视时的静电噪声)组成，而是遵循*一些*T4】的基本结构。

如果我们知道所有的图像都有共同点，那就更好了。进行图像压缩的最基本的方法之一是找到重复的像素流，给它们分配一个(较亮的)标签，并用该标签替换它们。

理想情况下，如果两个图像几乎相同，压缩程序可以存储两个图像，占用的空间不会比其中任何一个图像多。这应该也适用于图像的一部分。最后，我猜像无监督学习这样的模式发现机器应该擅长这个。

出于这项工作的目的，我们将使用我从 [Kaggle](https://www.kaggle.com/c/dogs-vs-cats) 下载的小猫图片数据集。这将保证大多数图片有一些共同的结构。

这里是 GitHub 项目的代码和今天的数据，如果你想跟进的话。然而，像往常一样，我将在这里添加最重要的片段。

但是在我们用代码弄脏我们的手之前，是时候学习一些深度学习了！

## [](#autoencoders-unsupervisedish-deep-learning)自动编码器:无监督- *ish* 深度学习

尽管我们称自动编码器为“无监督学习”，但它们实际上是一种伪装的监督学习算法。我知道，我也很震惊！

然而，它们确实有一个非常特殊的属性，这使得它们从普通的分类器中脱颖而出:**它们的输入和输出是相同的**。

### [](#training-an-autoencoder)训练一个自动编码器

当我们训练一个自动编码器时，我们实际上是在训练一个人工神经网络

*   取一个输入向量 *X* 。
*   应用一些数学知识(我现在不会进入深度学习的细节，但[这是我用来学习这些科目的书](https://www.bookdepository.com/book/9780262035613/?a_aid=strikingloo&chan=ws))。
*   返回另一个向量。在这种特殊情况下，我们希望它还是 X，或者尽可能接近 X。

然而，有一个技巧:在前馈过程(从输入到输出)中，神经网络会降低输入的维度，并在返回最后一层之前再次增加它。

### [](#the-curse-of-dimensionality)维度的诅咒

自动编码器将向量 *X* 作为输入，可能有很多分量。例如，对于 3 通道-*RGB*-分辨率为 48×48 的图片， *X* 将有 6912 个分量。即使它们中的每一个都只是一个浮点数，那也是 27Kb 的数据(非常小！)形象。这增加得很快。对如此多的元素进行所有数学运算所花费的时间也是非常相关的。

因此，我们必须将这个向量映射到一个更小的空间。在这个特殊的例子中，我试着把它缩小到原来的一半。然而，我们打算保留大部分数据。

### [](#architecture-of-an-autoencoder)自动编码器的架构

我们称降低输入向量维度的网络层为*编码器*，因为它*将数据编码*成一个更小的向量。

然后，我们对这个更小的向量进行操作，在我们的例子中，它的维数又减少了 2 倍。如果我们正在设计一个实际的图像压缩器，这将是我们将存储的输入版本，节省 75%的空间。然而，在训练期间，这只是在*解码*之前的中间步骤。

最后，使用减少的向量，自动编码器将不得不尽可能好地重建原始图像。

为了做到这一点，它将首先让它通过一个*解码器*层，该层再次将减少的向量映射到一个具有输入向量一半维度的向量。最后一层，我们得到一个与原始图像尺寸相同的矢量，希望非常相似。

Autoencoder 的层架构如下所示:

<figure>[![](../Images/9335d176db2e38a9cdfa60f556e40f5f.png)](https://res.cloudinary.com/practicaldev/image/fetch/s--RB8npvCd--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://cdn-images-1.medium.com/max/800/1%2AiDcAplzGhttLcYI56MIMxQ.png) 

<figcaption>来源:[中](https://towardsdatascience.com/deep-autoencoders-using-tensorflow-c68f075fd1a3)</figcaption>

</figure>

### [](#results-of-using-an-autoencoder)使用自动编码器的结果

训练自动编码器会有很多效果:

*   重建的图像不会与原始图像完全相似。
*   我们将能够保存更轻的简化向量，然后使用重建，只要它足够好(无论我们如何定义)，而不是原始图像。
*   我们现在将有一个神经网络，它已经学习了小猫图片中的一些潜在模式。

这最后一个是最有价值的结果。

自动编码器的一些行业应用包括:

*   有监督的深度学习模型的特征工程:我们不会直接向它们提供数据，而是通过自动编码器的隐藏层来提供数据。
*   异常检测:自动编码器在重建狗、风景或虫子的图片方面非常糟糕。这给了我们一种自动检查图片是否是一只小猫的方法。

现在你知道了我们为什么要做我们正在做的事情，让我们用一些实际的代码来实践一下吧！

## [](#training-an-autoencoder-with-tensorflow)用 Tensorflow 训练自动编码器

在本教程中，我们将使用 Tensorflow 的 eager API。我不得不说，这比以前的*会话*要直观得多，以至于我不会介意性能是否有所下降(我没有察觉)。

我们的数据集包含超过 8000 张小猫的图片，大小和颜色各不相同，位置也各不相同。你可以在 [GitHub 项目](https://github.com/StrikingLoo/AutoEncatter)中看到它，以及加载它的代码。

由于 PyPlot 处理 numpy 浮点数组的方式，并且为了加速网络的收敛，图像被加载为范围从 0 到 1 的浮点数组，而不是从 0 到 255。