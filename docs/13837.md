# 测试成功与失败

> 原文:[https://dev.to/punch/testing-for-success-vs-failure-30cp](https://dev.to/punch/testing-for-success-vs-failure-30cp)

当你构建一个东西，并调整它以满足它能覆盖的所有场景时，你如何/何时/在多大程度上测试它的失败？

比方说，我构建了一个监视器来观察两个特定指标之间的比率，我希望它在该比率低于 0.8 时向我发出警报，而不是低于 1(表示没有问题)或 0.9(表示我们可能有一些东西在自我修复，即自动扩展主机因不再需要而被终止)。

我构建了这个监视器，并根据以下历史示例调整了阈值:

1.  我们希望收到警报的时间，基于正在发生的事情以及当时的比率
2.  当我们预期比率不为 1 时，我们不需要发出警报，因为我们已经计划在该时间段内进行更改

我对此进行了研究，进行了测试，甚至对#1 和#2 做了一些新的示例测试。根据我迄今为止测试的所有内容，我构建的新监视器满足所有要求，并且会在我们希望它发出警报的所有时间发出警报，并且会忽略我们希望它忽略度量比率的所有时间。我将我的测试结果、我的研究、我的推理和显示器呈现给我的经理，他说:

### [](#you-need-to-come-up-with-an-example-of-where-this-monitor-fails)“你需要举出一个例子，说明这个显示器在哪里出了故障。”

# [](#is-he-right)*他说得对吗？*

记住，我有:

*   测试了不同的指标和组合/比率，以找到监控这些场景的最佳方式
*   调整了我的阈值，以满足我不想让监视器提醒我们的时候

测试未知的未知总是困难的。在这种情况下，我被要求制作一台*完全完美的显示器，并且**在未来不需要调整**，即使我们的基础设施发生变化*。

可以/应该这样做吗？如何/为什么/为什么不？