# Devicon 查找-二分搜索法实验

> 原文：<https://dev.to/coreyja/devicon-lookup---binary-search-experiment-1ine>

*原贴于[coreyja.com](https://coreyja.com/devicon-binary-search/)T3】*

## 背景

最近我写了，[写了关于](https://dev.to/coreyja/vim-fzf-with-devicons-11ee)的博客，写了 [`devicon-lookup`](https://github.com/coreyja/devicon-lookup) 工具。它旨在用于 VIM 和 fzf 中，为相应的文件类型提供图标。它被发布到了 Rust 子 reddit 上，并得到了一些评论。我和一位评论者聊了聊一些可能的速度改进，他提到他可能会使用一个排序列表，为查找做一个二分搜索法，而不是花时间构建一个散列表。

我决定尝试一下，这是一篇解释我所做的和我发现的结果的博客文章！

## 已有实现

现有的实现使用 Rust crate `lazy_static`来创建一个静态的运行时 HashMap，然后程序使用它来执行从文件扩展名到 devicon 符号的查找。

## 实验

### 二分搜索法

二分搜索法是在排序列表中搜索特定值的有效方式。第一步是初始化 HashMap，并将其转换成一个排序数组。因为我已经对 HashMap 插入进行了代码清洁排序，所以这就像将 hash 改为元组数组一样简单。其中元组中的第一个元素是扩展，第二个值是符号。

```
const SYMBOLS: [(&str, &str); 97] = [
  ("ai", ""),
  ...
  ("zsh", ""),
  ]; 
```

然后我使用了 Rust 集合方法`binary_search_by_key`,该方法允许您传入正在搜索的值和一个 lambda，该 lambda 指定如何从底层对象中检索用于二分搜索法的`key`。我提供的 lambda 只是从元组中返回了扩展值。

```
 let index = SYMBOLS.binary_search_by_key(&extension, |&(ext, _sym)| ext); 
```

### 带 HashMap 缓存的二分搜索法

标准二分搜索法的结果并不比最初的实现好多少。所以我想看看添加 HashMap，cache 是否会有帮助。这个想法是，当你找到你需要的符号时，慢慢地建立散列表。这在理论上可以避免创建散列表的前期初始化成本。

这一部分花了我一段时间来正确地工作，这主要是由于与 Rust 的借用检查。有两件主要的事情帮助我克服了一些障碍。帮助我克服第一个障碍的是 Rust Lang 论坛的回答，它帮助我弄清楚如何使用 HashMap 作为与所有权相关的缓存。这个例子给了我一个很好的开始，特别是关于`to_owned()`的用法。[https://users . rust-lang . org/t/borrow-checker-stopping-update-to-hashmap-cache/5300/3](https://users.rust-lang.org/t/borrow-checker-stopping-update-to-hashmap-cache/5300/3)

第二是意识到我可能希望缓存散列表是`<String,String>`而不是之前的`<&str,&str>`。之前我使用的是引用类型，因为之前我在 HashMap 中处理的所有字符串都是静态的。一旦我做了这个改变，我就能够让我的代码编译起来更容易。

这是位于 [GitHub](https://github.com/coreyja/devicon-lookup/tree/binary-search) 的`binary-search`分支上的代码的当前状态

## 结果

会有两部分结果。其中一台是 Chromebook，我在那里做了大部分开发工作；另一台是 Macbook Pro 笔记本电脑，用于比较我的日常工作站。

在所有的结果中，我首先准备一个小的和大的文件`~/tmp/$SIZE.txt`,它将包含大量的例子。这个集合将在机器之间保持一致，以使它们更具可比性。该文件是通过在我的 Chromebook 的主目录中列出文件而生成的，出于隐私原因将不会发布。

所有时间测试都是用[超精细](https://github.com/sharkdp/hyperfine)完成的

### Chromebook

#### 小

| 不同的 | 平均值[毫秒] | 最小…最大值[毫秒] |
| --- | --- | --- |
| 基线 | 10.4 ± 6.5 | 3.3…31.7 |
| 平原 | 10.2 ± 6.2 | 3.4…30.4 |
| 藏起 | 9.5 ± 5.8 | 2.7…29.9 |

#### 大

| 不同的 | 平均 | 最小值…最大值[s] |
| --- | --- | --- |
| 基线 | 3.816 ± 0.082 | 3.714…3.948 |
| 平原 | 3.847 ± 0.177 | 3.629…4.164 |
| 藏起 | 4.157 ± 0.288 | 3.815…4.591 |

### Macbook

#### 小

| 不同的 | 平均值[毫秒] | 最小…最大值[毫秒] |
| --- | --- | --- |
| 基线 | 4.0 ± 0.8 | 3.0…8.7 |
| 平原 | 3.8 ± 0.7 | 3.1…11.1 |
| 藏起 | 3.7 ± 0.5 | 3.1…9.8 |

#### 大

| 不同的 | 平均值[毫秒] | 最小…最大值[毫秒] |
| --- | --- | --- |
| 基线 | 835.6 ± 27.2 | 817.0…909.8 |
| 平原 | 818.0 ± 8.0 | 805.7…832.6 |
| 藏起 | 948.8 ± 7.8 | 942.6…967.0 |

## 思想

这些结果给我留下的第一个印象是，我增加缓存的“改进”并不是程序整体速度的改进。我想知道是由于我天真的实现，还是想法根本就是有缺陷的。我敢打赌我的实现还可以改进，但是这些最初的结果并不是最有希望的。

总的来说，在这些结果中，普通二分搜索法的表现可能优于基线实现，但是结果非常小。

这里最让我惊讶的是，在 Macbook 上，大样本运行速度最快的是普通二分搜索法。我认为对于小的集合来说这可能是真的，我们做了更少的查找，这超过了 HashMap 插入的成本。然而，当我重新运行测试时，我并没有始终如一地得到这样的结果。

在我看来，在普通二分搜索法和散列表查找之间，瓶颈可能在代码的其他地方。我会想象它在木卫一上，但我还没有调查这种说法。

## 下一步

这是一个有趣的实验，我学到了很多关于 Rust 所有权模型和借用检查器的知识！然而，结果似乎并没有显示出实质性的性能改进。从概念上来说，我更喜欢 HashMap 方法，因为它*应该*有最快的查找速度，所以我想我暂时会坚持使用它。将来，我可能会更多地研究将运行时散列表转换为编译时散列表的能力。